data:
  train_ratio: 0.85
  test_val_ratio: 0.35
  data_dir: /root/dataset/dataset
  dataset_name: "Addresso"     # "Ita-PVS" | "Neurovoz" | "Addresso"
  target_sr: 16000
  mono: true
  normalize: "peak"           # "peak" | "rms"
  fixed_duration_s: 5.0
  resample: true
  pad_mode: "silence"         # zeri
  label_map: { healthy: 0, alzheimer: 1 }

model:
  dropout: 0.6                            # ⬆️ Aumentato ulteriormente per combattere overfitting
  branch: "classical_mlp"     # "classical_svm" | "classical_mlp" | "cnn" | "transformers_mlp"
  cnn:
    in_type: "waveform"                      # "waveform" | "spectrogram" - waveform per semplicità
  mlp:
    hidden_layers: [32]                    # ⬇️ Ulteriormente semplificato per dataset piccolo
    dropout: 0.6                           # ⬆️ Aumentato per prevenire overfitting severo
    class_weight: "balanced"               # CRITICO: bilancia classi per migliorare recall classe 0
  svm:
    kernel: "linear"                       # Linear per dataset piccolo (meno overfitting)
    C: 1.0                                 # ⬇️ Ulteriormente ridotto per meno overfitting
    gamma: "scale"                         # Scale per bilanciamento migliore
    class_weight: "balanced"               # CRITICO: bilancia classi sbilanciate

features:
  classical:
    n_mfcc: 20                             # Aumentato per più informazioni
    mfcc_delta: true                       # Delta features per dinamica temporale
    mfcc_delta2: true                      # Delta-delta per accelerazione
    energy: true                           # Energia RMS
    pitch: true                            # Pitch fondamentale (importante per voce)
    pitch_method: "pyin"                   # Metodo PYIN per pitch robusto
    pitch_fmin: 50                         # Frequenza minima pitch (voce umana)
    pitch_fmax: 400                        # Frequenza massima pitch
    jitter_shimmer: true                   # Variabilità pitch e ampiezza
    spectral_features: true                # Features spettrali aggiuntive
    zero_crossing_rate: true               # Tasso attraversamento zero
  spectrogram:
    n_mels: 16                             # ⬇️ Ridotto da 32 per dataset piccolo (meno complessità)
    n_fft: 128                             # ⬇️ Ridotto da 256 per evitare overfitting
    hop_length: 128                        # Valore standard ottimizzato
    log: true
  transformers:
    model_name: "facebook/wav2vec2-base-960h"     # Miglior modello dai test (83.05% accuracy)
    pooling: "mean"                             # "cls" | "mean"
    freeze_backbone: false                      # Unfreeze per fine-tuning completo
    max_length: 32000                          # ⬇️ Ridotto da 48000 per dataset piccolo (2s * 16kHz)
    layer: -1                                  # Usa ultimo layer per rappresentazioni migliori
                                                # Modelli disponibili:
                                                # - facebook/wav2vec2-base-960h
                                                # - ALM/wav2vec2-base-audioset
                                                # - facebook/hubert-base-ls960
                                                # - ALM/hubert-base-audioset
                                                # - microsoft/wavlm-base-plus
                                                # - microsoft/wavlm-base

training:
  epochs: 15                              # ⬆️ Aumentato per convergenza migliore con LR basso
  batch_size: 4                           # ⬇️ Ulteriormente ridotto per gradiente più preciso
  optimizer: adamw                         # AdamW per migliore regolarizzazione
  max_lr: 0.00005                         # ⬇️ Dimezzato per apprendimento più graduale
  min_lr: 0.0000005                       # ⬇️ Min LR proporzionale (1/100 del max)
  warmup_ratio: 0.4                       # ⬆️ Warmup più lungo per stabilità
  weight_decay: 0.1                       # ⬆️ Aumentato per più regolarizzazione
  checkpoint_dir: checkpoints/
  model_name: best_model
  device: "cuda"              # "cuda" | "mps" | "cpu"
  evaluation_metric: accuracy
  best_metric_lower_is_better: false
  seed: 42  
  # Validation Split
  validation_split: 0.15                     # ⬇️ Ridotto da 0.20 per massimizzare training data

plot: [accuracy, loss]