data:
  train_ratio: 0.85
  test_val_ratio: 0.35
  data_dir: /root/dataset/dataset
  dataset_name: "Neurovoz"     # "Ita-PVS" | "Neurovoz" | "Addresso"
  target_sr: 16000
  mono: true
  normalize: "peak"           # "peak" | "rms"
  fixed_duration_s: 5.0
  resample: true
  pad_mode: "silence"         # zeri
  label_map: { healthy: 0, parkinson: 1 }

model:
  dropout: 0.25
  branch: "transformers_mlp"     # "classical_svm" | "classical_mlp" | "cnn" | "transformers_mlp"
  cnn:
    in_type: "waveform"       # "waveform" | "spectrogram"
  mlp:
    hidden: [512, 256, 128]                 # Architettura più profonda per migliori prestazioni
    dropout: 0.3                           # Dropout aumentato per prevenire overfitting
  svm:
    kernel: "rbf"
    C: 1.0
    gamma: "scale"

features:
  classical:
    n_mfcc: 13
    mfcc_delta: true
    energy: true
    pitch: false
    jitter_shimmer: true
  spectrogram:
    n_mels: 32                             # Ridotto da 64 per velocità
    n_fft: 256                             # Ridotto da 400 per velocità  
    hop_length: 128                        # Ridotto da 160 per velocità
    log: true
  transformers:
    model_name: "facebook/wav2vec2-base-960h"   # Modello più potente per migliori embedding
    pooling: "mean"                             # "cls" | "mean"
    freeze_backbone: false                      # Unfreeze per fine-tuning completo
    max_length: 64000                          # Aumentato per catturare più contesto (4s * 16kHz)
    layer: -1                                  # Usa ultimo layer per rappresentazioni migliori
                                                # Modelli disponibili:
                                                # - facebook/wav2vec2-base-960h
                                                # - ALM/wav2vec2-base-audioset
                                                # - facebook/hubert-base-ls960
                                                # - ALM/hubert-base-audioset
                                                # - microsoft/wavlm-base-plus
                                                # - microsoft/wavlm-base

training:
  epochs: 35 # Aumentato per permettere convergenza migliore
  batch_size: 48                           # Ridotto per stabilità e gradiente più preciso
  optimizer: adamw                         # AdamW per migliore regolarizzazione
  max_lr: 0.0008                          # LR leggermente ridotto per convergenza stabile
  min_lr: 0.000008                        # Min LR proporzionalmente ridotto
  warmup_ratio: 0.18                      # Warmup più lungo per convergenza graduale
  weight_decay: 0.01                      # Aggiunta regolarizzazione L2
  checkpoint_dir: checkpoints/
  model_name: best_model
  device: "cuda"              # "cuda" | "mps" | "cpu"
  evaluation_metric: accuracy
  best_metric_lower_is_better: false
  seed: 42  
  # Validation Split
  validation_split: 0.22                     # Validation split leggermente aumentato per valutazione più robusta

plot: [accuracy, loss]