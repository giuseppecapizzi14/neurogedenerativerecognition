data:
  train_ratio: 0.85
  test_val_ratio: 0.35
  data_dir: /root/dataset/dataset
  dataset_name: "Neurovoz"     # "Ita-PVS" | "Neurovoz" | "Addresso"
  target_sr: 16000
  mono: true
  normalize: "peak"           # "peak" | "rms"
  fixed_duration_s: 5.0
  resample: true
  pad_mode: "silence"         # zeri
  label_map: { healthy: 0, parkinson: 1 }

model:
  dropout: 0.25
  branch: "classical_mlp"     # "classical_svm" | "classical_mlp" | "cnn" | "transformers_mlp"
  cnn:
    in_type: "waveform"       # "waveform" | "spectrogram"
  mlp:
    hidden: [256, 128]                         # Aumentato per maggiore capacità di apprendimento
    dropout: 0.2                               # Aumentato dropout per prevenire overfitting
  svm:
    kernel: "rbf"
    C: 1.0
    gamma: "scale"

features:
  classical:
    n_mfcc: 13
    mfcc_delta: true
    energy: true
    pitch: false
    jitter_shimmer: true
  spectrogram:
    n_mels: 32                             # Ridotto da 64 per velocità
    n_fft: 256                             # Ridotto da 400 per velocità  
    hop_length: 128                        # Ridotto da 160 per velocità
    log: true
  transformers:
    model_name: "facebook/wav2vec2-base"   # Modello più leggero per velocità
    pooling: "mean"                             # "cls" | "mean"
    freeze_backbone: true                       # Congela backbone per velocità
    max_length: 48000                          # Limita lunghezza input (3s * 16kHz)
    layer: -2                                  # Usa layer intermedio invece dell'ultimo
                                                # Modelli disponibili:
                                                # - facebook/wav2vec2-base-960h
                                                # - ALM/wav2vec2-base-audioset
                                                # - facebook/hubert-base-ls960
                                                # - ALM/hubert-base-audioset
                                                # - microsoft/wavlm-base-plus
                                                # - microsoft/wavlm-base

training:
  epochs: 30  # Aumentato per permettere maggiore convergenza
  batch_size: 64                            # Manteniamo per stabilità
  optimizer: adam
  max_lr: 0.001                            # Ridotto per convergenza più stabile
  min_lr: 0.00001                          # Min LR più basso per fine-tuning
  warmup_ratio: 0.15                       # Warmup aumentato per stabilità
  checkpoint_dir: checkpoints/
  model_name: best_model
  device: "cuda"              # "cuda" | "mps" | "cpu"
  evaluation_metric: accuracy
  best_metric_lower_is_better: false
  seed: 42  
  # Validation Split
  validation_split: 0.2                     # 20% dei dati per validation

plot: [accuracy, loss]
